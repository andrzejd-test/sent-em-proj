{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kopia sentence tasks project.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "1QJ5qH36ocYv"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9O7Zmayynbzw",
        "colab_type": "text"
      },
      "source": [
        "# Użycie Power Means w Senteval - projekt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QJ5qH36ocYv",
        "colab_type": "text"
      },
      "source": [
        "## Przygotowanie narzędzi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dERyH8wupfu7",
        "colab_type": "code",
        "outputId": "e2309f76-def4-46bd-8408-daef571ecdda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "!git clone https://github.com/facebookresearch/SentEval \\\n",
        "&& cd SentEval \\\n",
        "&& pip install . \\\n",
        "&& cd ./data/downstream/ \\\n",
        "&& ./get_transfer_data.bash\n",
        "\n",
        "!cd /content/ \\\n",
        " && curl -Lo glove.840B.300d.zip http://nlp.stanford.edu/data/glove.840B.300d.zip \\\n",
        " && unzip glove.840B.300d.zip \\\n",
        " && rm glove.840B.300d.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'SentEval'...\n",
            "remote: Enumerating objects: 687, done.\u001b[K\n",
            "remote: Total 687 (delta 0), reused 0 (delta 0), pack-reused 687\u001b[K\n",
            "Receiving objects: 100% (687/687), 33.25 MiB | 19.79 MiB/s, done.\n",
            "Resolving deltas: 100% (431/431), done.\n",
            "Cloning into 'mosesdecoder'...\n",
            "remote: Enumerating objects: 24, done.\u001b[K\n",
            "remote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "^C\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0   315    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0   352    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  3 2075M    3 79.5M    0     0  53.4M      0  0:00:38  0:00:01  0:00:37 68.5M^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WlGUDA-pawv",
        "colab_type": "text"
      },
      "source": [
        "## Wstęp teoretyczny\n",
        "\n",
        "Krotkie overview danych na jakich pracujemy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HV4kbc9plZd",
        "colab_type": "text"
      },
      "source": [
        "### Power Means\n",
        "\n",
        "Na chama wzory i je opisac - co dlaczego i jak\n",
        "\n",
        "Power means:\n",
        "$$\n",
        "(\\frac{x_1^p + ... + x_n^p}{n})^{1/p}\n",
        "$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KI6vkBVpqZx",
        "colab_type": "text"
      },
      "source": [
        "### Senteval - omowienie\n",
        "\n",
        "o samej libce, jak porownej, na czym - transfer tasks krotko mna czym polga"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STuI1OvZpgB4",
        "colab_type": "text"
      },
      "source": [
        "## Implementacja"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWGCwu65Fos4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, unicode_literals\n",
        "\n",
        "import sys\n",
        "import io\n",
        "import numpy as np\n",
        "import logging\n",
        "import senteval"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7tMr3ZbFvzI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH_TO_SENTEVAL = '../'\n",
        "PATH_TO_DATA = '/content/SentEval/data'\n",
        "PATH_TO_VEC = '/content/glove.840B.300d.txt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "al8fZ39NFak-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gen_mean(values: list, p: float):\n",
        "    '''\n",
        "    Compute power mean from values\n",
        "    :param values: \n",
        "    :param p:\n",
        "    :return:\n",
        "    '''\n",
        "    p = float(p)\n",
        "    return np.power(\n",
        "        np.mean(\n",
        "            np.power(\n",
        "                np.array(values, dtype=complex),\n",
        "                p),\n",
        "            axis=0),\n",
        "        1 / p\n",
        "    )\n",
        "\n",
        "\n",
        "def get_sentence_embedding(sentence: str, embeddings_vectors: list, embeddings_dimensionality: int):\n",
        "    '''\n",
        "    Function compute full sentence into vector by power mean.\n",
        "    :param sentence: sentence from batch set\n",
        "    :param embeddings_vectors: all embeddings vector for transfer task\n",
        "    :param embeddings_dimensionality: dimension of word embedding vector\n",
        "    :return: sentence embedding for sentence\n",
        "    '''\n",
        "    word_embeddings = []\n",
        "    p = 2.0\n",
        "    for tok in sentence:\n",
        "        if tok in embeddings_vectors:\n",
        "            word_embeddings.append(embeddings_vectors[tok])\n",
        "\n",
        "    if not word_embeddings:\n",
        "        return np.zeros(embeddings_dimensionality)\n",
        "    else:\n",
        "        return [gen_mean(word_embeddings, p).real]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QrrQxtbFX4W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_dictionary(sentences: list, threshold=0):\n",
        "    '''\n",
        "    map id to word and word to id\n",
        "    :param sentences: all sentences for transfer task\n",
        "    :param threshold: \n",
        "    :return: \n",
        "    '''\n",
        "    words = {}\n",
        "    for s in sentences:\n",
        "        for word in s:\n",
        "            words[word] = words.get(word, 0) + 1\n",
        "\n",
        "    if threshold > 0:\n",
        "        newwords = {}\n",
        "        for word in words:\n",
        "            if words[word] >= threshold:\n",
        "                newwords[word] = words[word]\n",
        "        words = newwords\n",
        "    words['<s>'] = 1e9 + 4\n",
        "    words['</s>'] = 1e9 + 3\n",
        "    words['<p>'] = 1e9 + 2\n",
        "\n",
        "    sorted_words = sorted(words.items(), key=lambda x: -x[1])  # inverse sort\n",
        "    id2word = []\n",
        "    word2id = {}\n",
        "    for i, (w, _) in enumerate(sorted_words):\n",
        "        id2word.append(w)\n",
        "        word2id[w] = i\n",
        "\n",
        "    return id2word, word2id\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpqpnn7YFU-g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_wordvec(path_to_vec: str, word2id):\n",
        "    '''\n",
        "    :param path_to_vec: path to word embeddings file (glove) \n",
        "    :param word2id: dict mapping word to word id\n",
        "    :return: word embeddings for dictionary\n",
        "    '''\n",
        "    word_vec = {}\n",
        "\n",
        "    with io.open(path_to_vec, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            word, vec = line.split(' ', 1)\n",
        "            if word in word2id:\n",
        "                word_vec[word] = np.fromstring(vec, sep=' ')\n",
        "\n",
        "    logging.info('Found {0} words with word vectors, out of \\\n",
        "        {1} words'.format(len(word_vec), len(word2id)))\n",
        "    return word_vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGsmvX8oFRIu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare(params, samples):\n",
        "    '''\n",
        "    Load word embeddings and map dictionary to word vector\n",
        "    :param params: parameters SentEval and our methods (e.g. words vector, dimention of vector)\n",
        "    :param samples: list of all sentences from transfer tasks\n",
        "    :return: void\n",
        "    '''\n",
        "    _, params.word2id = create_dictionary(samples)\n",
        "    params.word_vec = get_wordvec(PATH_TO_VEC, params.word2id)\n",
        "    params.wvec_dim = 300\n",
        "    return\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdE2nIbWFQbu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batcher(params, batch):\n",
        "    '''\n",
        "    Computing power means from batch\n",
        "    :param params: SentEval params and prepared word vectors\n",
        "    :param batch: part of sentences from transfer tasks \n",
        "    :return: computed embeddings\n",
        "    '''\n",
        "    batch = [sent if sent != [] else ['.'] for sent in batch]\n",
        "    embeddings = []\n",
        "\n",
        "    for sent in batch:\n",
        "        sentvec = get_sentence_embedding(sent, params.word_vec, params.wvec_dim)\n",
        "        embeddings.append(sentvec)\n",
        "\n",
        "    embeddings = np.vstack(embeddings)\n",
        "    return embeddings"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bj0uneB-FIhS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params_senteval = {'task_path': PATH_TO_DATA, 'usepytorch': True, 'kfold': 5}\n",
        "params_senteval['classifier'] = {'nhid': 0, 'optim': 'rmsprop', 'batch_size': 128,\n",
        "                                 'tenacity': 3, 'epoch_size': 2}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0xXRvcTuYiX",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "*   `task_path` - ścieżka do folderu z _transfer tasks_\n",
        "*   `usepytorch` - czy do obliczeń jest wykorzystywana biblioteka `PyTorch`\n",
        "*   `kfold` - k-fold validation dla tasków: **MR** i **CR**\n",
        "*   `classifier`:\n",
        "    * `nhid` - ilość ukrytych warstw (dla `0` jest to *LogisticRegression*)\n",
        "    * `optim` - optimizer\n",
        "    * `batch_size` - rozmiar batch\n",
        "    * `tenacity` - po ilu powtórzeniach przerywane są obliczenia, gdy nie wzrośnie `dev_acc`\n",
        "    * `epoch_size` - \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ri7DC8jFFyb",
        "colab_type": "code",
        "outputId": "4282fae7-6c5d-4e96-d328-b6ed26cced4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        }
      },
      "source": [
        "logging.basicConfig(format='%(asctime)s : %(message)s', level=logging.DEBUG)\n",
        "\n",
        "se = senteval.engine.SE(params_senteval, batcher, prepare)\n",
        "transfer_tasks = ['MR', 'CR', 'SST2']\n",
        "results = se.eval(transfer_tasks)\n",
        "print(results)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-09-09 21:04:40,513 : ***** Transfer task : MR *****\n",
            "\n",
            "\n",
            "2019-09-09 21:04:47,501 : Found 18490 words with word vectors, out of         20328 words\n",
            "2019-09-09 21:04:47,513 : Generating sentence embeddings\n",
            "2019-09-09 21:04:48,898 : Generated sentence embeddings\n",
            "2019-09-09 21:04:48,900 : Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation\n",
            "2019-09-09 21:05:09,760 : Best param found at split 1: l2reg = 0.0001                 with score 68.07\n",
            "2019-09-09 21:05:22,272 : Best param found at split 2: l2reg = 0.0001                 with score 61.86\n",
            "2019-09-09 21:05:36,098 : Best param found at split 3: l2reg = 0.001                 with score 68.72\n",
            "2019-09-09 21:05:48,385 : Best param found at split 4: l2reg = 0.001                 with score 67.26\n",
            "2019-09-09 21:06:01,411 : Best param found at split 5: l2reg = 1e-05                 with score 66.62\n",
            "2019-09-09 21:06:01,917 : Dev acc : 66.51 Test acc : 66.95\n",
            "\n",
            "2019-09-09 21:06:01,923 : ***** Transfer task : CR *****\n",
            "\n",
            "\n",
            "2019-09-09 21:06:32,743 : Found 5477 words with word vectors, out of         5677 words\n",
            "2019-09-09 21:06:32,830 : Generating sentence embeddings\n",
            "2019-09-09 21:06:33,311 : Generated sentence embeddings\n",
            "2019-09-09 21:06:33,313 : Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation\n",
            "2019-09-09 21:06:37,642 : Best param found at split 1: l2reg = 1e-05                 with score 70.82\n",
            "2019-09-09 21:06:42,123 : Best param found at split 2: l2reg = 1e-05                 with score 68.04\n",
            "2019-09-09 21:06:45,960 : Best param found at split 3: l2reg = 1e-05                 with score 66.03\n",
            "2019-09-09 21:06:49,717 : Best param found at split 4: l2reg = 0.01                 with score 67.13\n",
            "2019-09-09 21:06:53,520 : Best param found at split 5: l2reg = 0.001                 with score 64.28\n",
            "2019-09-09 21:06:53,743 : Dev acc : 67.26 Test acc : 68.13\n",
            "\n",
            "2019-09-09 21:06:53,745 : ***** Transfer task : SST Binary classification *****\n",
            "\n",
            "\n",
            "2019-09-09 21:07:22,950 : Found 16530 words with word vectors, out of         17561 words\n",
            "2019-09-09 21:07:22,957 : Computing embedding for train\n",
            "2019-09-09 21:07:28,972 : Computed train embeddings\n",
            "2019-09-09 21:07:28,973 : Computing embedding for dev\n",
            "2019-09-09 21:07:29,099 : Computed dev embeddings\n",
            "2019-09-09 21:07:29,100 : Computing embedding for test\n",
            "2019-09-09 21:07:29,326 : Computed test embeddings\n",
            "2019-09-09 21:07:29,327 : Training pytorch-MLP-nhid0-rmsprop-bs128 with standard validation..\n",
            "2019-09-09 21:07:47,612 : [('reg:1e-05', 71.1), ('reg:0.0001', 71.33), ('reg:0.001', 72.13), ('reg:0.01', 70.64)]\n",
            "2019-09-09 21:07:47,614 : Validation : best param found is reg = 0.001 with score             72.13\n",
            "2019-09-09 21:07:47,615 : Evaluating...\n",
            "2019-09-09 21:07:52,414 : \n",
            "Dev acc : 72.13 Test acc : 71.61 for             SST Binary classification\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'MR': {'devacc': 66.51, 'acc': 66.95, 'ndev': 10662, 'ntest': 10662}, 'CR': {'devacc': 67.26, 'acc': 68.13, 'ndev': 3775, 'ntest': 3775}, 'SST2': {'devacc': 72.13, 'acc': 71.61, 'ndev': 872, 'ntest': 1821}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Vx0wMxgpwjj",
        "colab_type": "text"
      },
      "source": [
        "## Ewaluacja"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HG1q0makqtQa",
        "colab_type": "text"
      },
      "source": [
        "Porownanie baseline przy innych, wzmiankowanych w conneau sentence embeddingsach dla tych samych transfer taskow.\n",
        "\n",
        "Wykres slupkowy/box plot(?) do porownania wynikow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOw6LakHqKP8",
        "colab_type": "text"
      },
      "source": [
        "## Wnioski"
      ]
    }
  ]
}